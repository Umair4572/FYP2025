{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Assessment - XGBoost Model Training\n",
    "\n",
    "This notebook demonstrates how to train and evaluate an XGBoost model for credit risk prediction using real lending club data.\n",
    "\n",
    "**Dataset**: Lending Club loan data  \n",
    "**Target**: Binary classification (0 = No default, 1 = Default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installation of Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\faheem\\appdata\\roaming\\python\\python313\\site-packages (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (1.15.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\faheem\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\faheem\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\faheem\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\faheem\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "✓ Packages installed successfully!\n",
      "You can now run the rest of the notebook.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost scikit-learn pandas numpy matplotlib seaborn scipy tqdm joblib\n",
    "print(\"✓ Packages installed successfully!\")\n",
    "print(\"You can now run the rest of the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.config import RAW_DATA_DIR, DATASET_CONFIG, MODELS_DIR, XGBOOST_PARAMS\n",
    "from src.data_loader import load_data\n",
    "from src.preprocessor import DataPreprocessor\n",
    "from src.feature_engineer import FeatureEngineer\n",
    "from src.models.xgboost_model import XGBoostModel\n",
    "from src.evaluation import ModelEvaluator\n",
    "from src.utils import setup_logging, set_seed\n",
    "\n",
    "# Setup\n",
    "setup_logging()\n",
    "set_seed(42)\n",
    "\n",
    "print(\"✓ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "Load training and test datasets. You can adjust `nrows` to control sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:43:32,672 - credit_risk_fyp.data_loader - INFO - Loading dataset from: c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\data\\raw\\lending_club_train.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "\n",
      "File size: 0.21 GB\n",
      "Loaded 50,000 rows\n",
      "\n",
      "Optimizing data types...\n",
      "Memory usage before optimization: 76.06 MB\n",
      "Memory usage after optimization: 60.75 MB\n",
      "Memory decreased by 20.1%\n",
      "\n",
      "Memory usage: 60.75 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:43:33,904 - credit_risk_fyp.data_loader - INFO - Successfully loaded 50,000 rows and 103 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 memory-consuming columns:\n",
      "  desc                          :     3.63 MB\n",
      "  title                         :     3.17 MB\n",
      "  purpose                       :     3.05 MB\n",
      "  emp_title                     :     3.02 MB\n",
      "  term                          :     2.81 MB\n",
      "  application_type              :     2.81 MB\n",
      "  earliest_cr_line              :     2.72 MB\n",
      "  emp_length                    :     2.65 MB\n",
      "  home_ownership                :     2.62 MB\n",
      "  zip_code                      :     2.57 MB\n",
      "\n",
      "Loaded 50,000 rows from lending_club_train.csv\n",
      "Features: 103\n",
      "\n",
      "Target distribution:\n",
      "default\n",
      "0    40037\n",
      "1     9963\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>default</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>desc</th>\n",
       "      <th>...</th>\n",
       "      <th>sec_app_inq_last_6mths</th>\n",
       "      <th>sec_app_mort_acc</th>\n",
       "      <th>sec_app_open_acc</th>\n",
       "      <th>sec_app_revol_util</th>\n",
       "      <th>sec_app_open_act_il</th>\n",
       "      <th>sec_app_num_rev_accts</th>\n",
       "      <th>sec_app_chargeoff_within_12_mths</th>\n",
       "      <th>sec_app_collections_12_mths_ex_med</th>\n",
       "      <th>sec_app_mths_since_last_major_derog</th>\n",
       "      <th>disbursement_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>pharmacist</td>\n",
       "      <td>6 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>130000.000000</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>TIGI Linea - Unilever</td>\n",
       "      <td>5 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>51769.859375</td>\n",
       "      <td>n</td>\n",
       "      <td>Borrower added on 09/04/12 &gt; To consolidate ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>Manager of Program Management</td>\n",
       "      <td>2 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>136000.000000</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>32875</td>\n",
       "      <td>60 months</td>\n",
       "      <td>Oracle Corporation</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>OWN</td>\n",
       "      <td>106000.000000</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>Enrichment Coordinator</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>123000.000000</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  default  loan_amnt        term                      emp_title  \\\n",
       "0   1        0      10000   36 months                     pharmacist   \n",
       "1   2        0      20000   36 months          TIGI Linea - Unilever   \n",
       "2   3        1      28000   60 months  Manager of Program Management   \n",
       "3   4        1      32875   60 months             Oracle Corporation   \n",
       "4   5        1      10000   36 months         Enrichment Coordinator   \n",
       "\n",
       "  emp_length home_ownership     annual_inc pymnt_plan  \\\n",
       "0    6 years       MORTGAGE  130000.000000          n   \n",
       "1    5 years       MORTGAGE   51769.859375          n   \n",
       "2    2 years           RENT  136000.000000          n   \n",
       "3   < 1 year            OWN  106000.000000          n   \n",
       "4    3 years           RENT  123000.000000          n   \n",
       "\n",
       "                                                desc  ...  \\\n",
       "0                                                NaN  ...   \n",
       "1    Borrower added on 09/04/12 > To consolidate ...  ...   \n",
       "2                                                NaN  ...   \n",
       "3                                                NaN  ...   \n",
       "4                                                NaN  ...   \n",
       "\n",
       "  sec_app_inq_last_6mths sec_app_mort_acc sec_app_open_acc sec_app_revol_util  \\\n",
       "0                    NaN              NaN              NaN                NaN   \n",
       "1                    NaN              NaN              NaN                NaN   \n",
       "2                    NaN              NaN              NaN                NaN   \n",
       "3                    NaN              NaN              NaN                NaN   \n",
       "4                    NaN              NaN              NaN                NaN   \n",
       "\n",
       "   sec_app_open_act_il  sec_app_num_rev_accts  \\\n",
       "0                  NaN                    NaN   \n",
       "1                  NaN                    NaN   \n",
       "2                  NaN                    NaN   \n",
       "3                  NaN                    NaN   \n",
       "4                  NaN                    NaN   \n",
       "\n",
       "  sec_app_chargeoff_within_12_mths  sec_app_collections_12_mths_ex_med  \\\n",
       "0                              NaN                                 NaN   \n",
       "1                              NaN                                 NaN   \n",
       "2                              NaN                                 NaN   \n",
       "3                              NaN                                 NaN   \n",
       "4                              NaN                                 NaN   \n",
       "\n",
       "   sec_app_mths_since_last_major_derog  disbursement_method  \n",
       "0                                  NaN                 Cash  \n",
       "1                                  NaN                 Cash  \n",
       "2                                  NaN                 Cash  \n",
       "3                                  NaN                 Cash  \n",
       "4                                  NaN                 Cash  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "train_path = RAW_DATA_DIR / DATASET_CONFIG['train_dataset']\n",
    "train_df = load_data(train_path, optimize=True, nrows=50000)  # Adjust nrows as needed\n",
    "\n",
    "print(f\"\\nLoaded {len(train_df):,} rows from {DATASET_CONFIG['train_dataset']}\")\n",
    "print(f\"Features: {train_df.shape[1]}\")\n",
    "\n",
    "# Show target distribution\n",
    "target_col = DATASET_CONFIG['target_column']\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(train_df[target_col].value_counts())\n",
    "\n",
    "# Show first few rows\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:43:33,947 - credit_risk_fyp.data_loader - INFO - Loading dataset from: c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\data\\raw\\lending_club_test.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "\n",
      "File size: 0.06 GB\n",
      "Loaded 10,000 rows\n",
      "\n",
      "Optimizing data types...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:43:34,248 - credit_risk_fyp.data_loader - INFO - Successfully loaded 10,000 rows and 103 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before optimization: 15.21 MB\n",
      "Memory usage after optimization: 12.13 MB\n",
      "Memory decreased by 20.2%\n",
      "\n",
      "Memory usage: 12.13 MB\n",
      "\n",
      "Top 10 memory-consuming columns:\n",
      "  desc                          :     0.73 MB\n",
      "  title                         :     0.63 MB\n",
      "  purpose                       :     0.61 MB\n",
      "  emp_title                     :     0.60 MB\n",
      "  term                          :     0.56 MB\n",
      "  application_type              :     0.56 MB\n",
      "  earliest_cr_line              :     0.54 MB\n",
      "  emp_length                    :     0.53 MB\n",
      "  home_ownership                :     0.52 MB\n",
      "  zip_code                      :     0.51 MB\n",
      "\n",
      "Loaded 10,000 rows from lending_club_test.csv\n",
      "Features: 103\n",
      "\n",
      "Target distribution:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "test_path = RAW_DATA_DIR / DATASET_CONFIG['test_dataset']\n",
    "test_df = load_data(test_path, optimize=True, nrows=10000)  # Adjust nrows as needed\n",
    "\n",
    "print(f\"\\nLoaded {len(test_df):,} rows from {DATASET_CONFIG['test_dataset']}\")\n",
    "print(f\"Features: {test_df.shape[1]}\")\n",
    "\n",
    "# Show target distribution\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(test_df[target_col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 42,500 samples\n",
      "Validation set: 7,500 samples\n",
      "Test set: 10,000 samples\n",
      "\n",
      "Train target distribution: {0: 34031, 1: 8469}\n",
      "Test target distribution: {}\n"
     ]
    }
   ],
   "source": [
    "id_col = DATASET_CONFIG['id_column']\n",
    "\n",
    "# Training data: Split into train and validation\n",
    "X_train_full = train_df.drop(columns=[target_col, id_col])\n",
    "y_train_full = train_df[target_col]\n",
    "\n",
    "# Split training data: 85% train, 15% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=y_train_full\n",
    ")\n",
    "\n",
    "# Test data\n",
    "X_test = test_df.drop(columns=[target_col, id_col])\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "print(f\"Train set: {len(X_train):,} samples\")\n",
    "print(f\"Validation set: {len(X_val):,} samples\")\n",
    "print(f\"Test set: {len(X_test):,} samples\")\n",
    "print(f\"\\nTrain target distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Test target distribution: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:43:34,398 - credit_risk_fyp.preprocessor - INFO - Fitting preprocessor on training data...\n",
      "2025-11-27 23:43:34,408 - credit_risk_fyp.preprocessor - INFO - Creating binary target variable...\n",
      "2025-11-27 23:43:34,433 - credit_risk_fyp.preprocessor - INFO - Removed 0 rows with uncertain/excluded status\n",
      "2025-11-27 23:43:34,436 - credit_risk_fyp.preprocessor - INFO - Target distribution:\n",
      "  Non-default (0): 34,031\n",
      "  Default (1): 8,469\n",
      "2025-11-27 23:43:34,486 - credit_risk_fyp.preprocessor - INFO - Identified 36 columns with >50.0% missing\n",
      "2025-11-27 23:43:34,505 - credit_risk_fyp.preprocessor - INFO - Identified 51 numerical and 14 categorical features\n",
      "2025-11-27 23:43:34,506 - credit_risk_fyp.preprocessor - INFO - Fitting imputers for missing values...\n",
      "2025-11-27 23:43:34,910 - credit_risk_fyp.preprocessor - INFO - Fitting encoders for 14 categorical features...\n",
      "2025-11-27 23:43:35,180 - credit_risk_fyp.preprocessor - INFO - Fitting scaler for numerical features...\n",
      "2025-11-27 23:43:35,208 - credit_risk_fyp.preprocessor - INFO - Calculating outlier statistics (method=iqr)...\n",
      "2025-11-27 23:43:35,309 - credit_risk_fyp.preprocessor - INFO - Preprocessor fitting complete\n",
      "2025-11-27 23:43:35,318 - credit_risk_fyp.preprocessor - INFO - Transforming data...\n",
      "2025-11-27 23:43:35,329 - credit_risk_fyp.preprocessor - INFO - Creating binary target variable...\n",
      "2025-11-27 23:43:35,354 - credit_risk_fyp.preprocessor - INFO - Removed 0 rows with uncertain/excluded status\n",
      "2025-11-27 23:43:35,356 - credit_risk_fyp.preprocessor - INFO - Target distribution:\n",
      "  Non-default (0): 34,031\n",
      "  Default (1): 8,469\n",
      "2025-11-27 23:43:35,879 - credit_risk_fyp.preprocessor - INFO - Transform complete. Shape: (42500, 65)\n",
      "2025-11-27 23:43:35,880 - credit_risk_fyp.preprocessor - INFO - Transforming data...\n",
      "2025-11-27 23:43:35,916 - credit_risk_fyp.preprocessor - WARNING - Found 3594 unseen categories in 'emp_title'\n",
      "2025-11-27 23:43:35,956 - credit_risk_fyp.preprocessor - WARNING - Found 848 unseen categories in 'title'\n",
      "2025-11-27 23:43:35,966 - credit_risk_fyp.preprocessor - WARNING - Found 4 unseen categories in 'zip_code'\n",
      "2025-11-27 23:43:35,973 - credit_risk_fyp.preprocessor - WARNING - Found 6 unseen categories in 'earliest_cr_line'\n",
      "2025-11-27 23:43:35,979 - credit_risk_fyp.preprocessor - WARNING - Found 6 unseen categories in 'revol_util'\n",
      "2025-11-27 23:43:36,066 - credit_risk_fyp.preprocessor - INFO - Transform complete. Shape: (7500, 65)\n",
      "2025-11-27 23:43:36,066 - credit_risk_fyp.preprocessor - INFO - Transforming data...\n",
      "2025-11-27 23:43:36,105 - credit_risk_fyp.preprocessor - WARNING - Found 4789 unseen categories in 'emp_title'\n",
      "2025-11-27 23:43:36,148 - credit_risk_fyp.preprocessor - WARNING - Found 1114 unseen categories in 'title'\n",
      "2025-11-27 23:43:36,157 - credit_risk_fyp.preprocessor - WARNING - Found 5 unseen categories in 'zip_code'\n",
      "2025-11-27 23:43:36,166 - credit_risk_fyp.preprocessor - WARNING - Found 9 unseen categories in 'earliest_cr_line'\n",
      "2025-11-27 23:43:36,171 - credit_risk_fyp.preprocessor - WARNING - Found 2 unseen categories in 'revol_util'\n",
      "2025-11-27 23:43:36,257 - credit_risk_fyp.preprocessor - INFO - Transform complete. Shape: (10000, 65)\n",
      "2025-11-27 23:43:36,268 - credit_risk_fyp.preprocessor - INFO - Saved preprocessor to c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\models\\preprocessor.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features after preprocessing: 65\n",
      "Train shape: (42500, 65)\n",
      "Val shape: (7500, 65)\n",
      "Test shape: (10000, 65)\n",
      "✓ Saved object to c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\models\\preprocessor.pkl\n",
      "\n",
      "✓ Preprocessor saved to c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\models\\preprocessor.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing data...\")\n",
    "preprocessor = DataPreprocessor()\n",
    "\n",
    "# Combine X_train and y_train for preprocessing\n",
    "train_df_combined = X_train.copy()\n",
    "train_df_combined[target_col] = y_train\n",
    "\n",
    "# Fit on training data\n",
    "X_train_processed, _ = preprocessor.fit_transform(train_df_combined)\n",
    "X_val_processed, _ = preprocessor.transform(X_val)\n",
    "X_test_processed, _ = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"\\nFeatures after preprocessing: {X_train_processed.shape[1]}\")\n",
    "print(f\"Train shape: {X_train_processed.shape}\")\n",
    "print(f\"Val shape: {X_val_processed.shape}\")\n",
    "print(f\"Test shape: {X_test_processed.shape}\")\n",
    "\n",
    "# Save preprocessor\n",
    "preprocessor_path = MODELS_DIR / 'preprocessor.pkl'\n",
    "preprocessor.save(preprocessor_path)\n",
    "print(f\"\\n✓ Preprocessor saved to {preprocessor_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:43:36,280 - credit_risk_fyp.feature_engineer - INFO - Fitting feature engineer...\n",
      "2025-11-27 23:43:36,284 - credit_risk_fyp.feature_engineer - INFO - Feature engineer fitting complete\n",
      "2025-11-27 23:43:36,285 - credit_risk_fyp.feature_engineer - INFO - Engineering features...\n",
      "2025-11-27 23:43:36,307 - credit_risk_fyp.feature_engineer - INFO - Creating ratio features...\n",
      "2025-11-27 23:43:36,312 - credit_risk_fyp.feature_engineer - INFO - Creating time-based features...\n",
      "2025-11-27 23:43:36,327 - credit_risk_fyp.feature_engineer - INFO - Creating credit behavior features...\n",
      "2025-11-27 23:43:36,332 - credit_risk_fyp.feature_engineer - INFO - Creating interaction features...\n",
      "2025-11-27 23:43:36,334 - credit_risk_fyp.feature_engineer - INFO - Creating aggregation features...\n",
      "2025-11-27 23:43:36,348 - credit_risk_fyp.feature_engineer - INFO - Creating binned features...\n",
      "2025-11-27 23:43:36,361 - credit_risk_fyp.feature_engineer - INFO - Created 20 new features (total: 85)\n",
      "2025-11-27 23:43:36,362 - credit_risk_fyp.feature_engineer - INFO - Engineering features...\n",
      "2025-11-27 23:43:36,368 - credit_risk_fyp.feature_engineer - INFO - Creating ratio features...\n",
      "2025-11-27 23:43:36,371 - credit_risk_fyp.feature_engineer - INFO - Creating time-based features...\n",
      "2025-11-27 23:43:36,374 - credit_risk_fyp.feature_engineer - INFO - Creating credit behavior features...\n",
      "2025-11-27 23:43:36,380 - credit_risk_fyp.feature_engineer - INFO - Creating interaction features...\n",
      "2025-11-27 23:43:36,382 - credit_risk_fyp.feature_engineer - INFO - Creating aggregation features...\n",
      "2025-11-27 23:43:36,386 - credit_risk_fyp.feature_engineer - INFO - Creating binned features...\n",
      "2025-11-27 23:43:36,391 - credit_risk_fyp.feature_engineer - INFO - Created 20 new features (total: 85)\n",
      "2025-11-27 23:43:36,392 - credit_risk_fyp.feature_engineer - INFO - Engineering features...\n",
      "2025-11-27 23:43:36,400 - credit_risk_fyp.feature_engineer - INFO - Creating ratio features...\n",
      "2025-11-27 23:43:36,402 - credit_risk_fyp.feature_engineer - INFO - Creating time-based features...\n",
      "2025-11-27 23:43:36,406 - credit_risk_fyp.feature_engineer - INFO - Creating credit behavior features...\n",
      "2025-11-27 23:43:36,411 - credit_risk_fyp.feature_engineer - INFO - Creating interaction features...\n",
      "2025-11-27 23:43:36,414 - credit_risk_fyp.feature_engineer - INFO - Creating aggregation features...\n",
      "2025-11-27 23:43:36,419 - credit_risk_fyp.feature_engineer - INFO - Creating binned features...\n",
      "2025-11-27 23:43:36,426 - credit_risk_fyp.feature_engineer - INFO - Created 20 new features (total: 85)\n",
      "2025-11-27 23:43:36,429 - credit_risk_fyp.feature_engineer - INFO - Saved feature engineer to c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\models\\feature_engineer.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features...\n",
      "\n",
      "Features after engineering: 85\n",
      "Train shape: (42500, 85)\n",
      "Val shape: (7500, 85)\n",
      "Test shape: (10000, 85)\n",
      "✓ Saved object to c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\models\\feature_engineer.pkl\n",
      "\n",
      "✓ Feature engineer saved to c:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\models\\feature_engineer.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Engineering features...\")\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "# Fit on training data\n",
    "X_train_final = feature_engineer.fit_transform(X_train_processed)\n",
    "X_val_final = feature_engineer.transform(X_val_processed)\n",
    "X_test_final = feature_engineer.transform(X_test_processed)\n",
    "\n",
    "print(f\"\\nFeatures after engineering: {X_train_final.shape[1]}\")\n",
    "print(f\"Train shape: {X_train_final.shape}\")\n",
    "print(f\"Val shape: {X_val_final.shape}\")\n",
    "print(f\"Test shape: {X_test_final.shape}\")\n",
    "\n",
    "# Save feature engineer\n",
    "fe_path = MODELS_DIR / 'feature_engineer.pkl'\n",
    "feature_engineer.save(fe_path)\n",
    "print(f\"\\n✓ Feature engineer saved to {fe_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train XGBoost Model\n",
    "\n",
    "You can modify the parameters below to experiment with different configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:43:36,440 - credit_risk_fyp.models.xgboost - INFO - Training XGBoost model...\n",
      "2025-11-27 23:43:36,441 - credit_risk_fyp.models.xgboost - INFO - Training set size: 42,500 samples, 85 features\n",
      "2025-11-27 23:43:36,446 - credit_risk_fyp.models.xgboost - INFO - Class distribution - 0: 34,031, 1: 8,469\n",
      "2025-11-27 23:43:36,448 - credit_risk_fyp.models.xgboost - INFO - Scale pos weight: 4.0183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "Parameters: {'objective': 'binary:logistic', 'eval_metric': 'auc', 'tree_method': 'gpu_hist', 'predictor': 'gpu_predictor', 'max_depth': 8, 'learning_rate': 0.05, 'n_estimators': 1000, 'subsample': 0.8, 'colsample_bytree': 0.8, 'min_child_weight': 3, 'gamma': 0.1, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'scale_pos_weight': 5, 'random_state': 42, 'n_jobs': -1, 'early_stopping_rounds': 50, 'verbose_eval': 50}\n",
      "\n",
      "This may take a few minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 23:43:36,504 - credit_risk_fyp.models.xgboost - INFO - Validation set size: 7,500 samples\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "Invalid Input: 'gpu_hist', valid values are: {'approx', 'auto', 'exact', 'hist'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Initialize and train\u001b[39;00m\n\u001b[32m     22\u001b[39m xgb_model = XGBoostModel(params=params)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mxgb_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[32m     30\u001b[39m model_path = MODELS_DIR / \u001b[33m'\u001b[39m\u001b[33mxgboost_model.pkl\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Faheem\\Desktop\\Umair FYP\\FYP2025\\credit_risk_fyp\\src\\models\\xgboost_model.py:98\u001b[39m, in \u001b[36mXGBoostModel.train\u001b[39m\u001b[34m(self, X_train, y_train, X_val, y_val, verbose)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m     96\u001b[39m evals_result = {}\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_estimators\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    106\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Store best iteration\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m.best_iteration = \u001b[38;5;28mself\u001b[39m.model.best_iteration\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:194\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    189\u001b[39m     callbacks.append(EarlyStopping(rounds=early_stopping_rounds, maximize=maximize))\n\u001b[32m    190\u001b[39m cb_container = CallbackContainer(\n\u001b[32m    191\u001b[39m     callbacks, metric=custom_metric, output_margin=\u001b[38;5;28mcallable\u001b[39m(obj)\n\u001b[32m    192\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m bst = \u001b[43mcb_container\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbefore_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iteration, num_boost_round):\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\callback.py:187\u001b[39m, in \u001b[36mCallbackContainer.before_training\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Function called before training.\"\"\"\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     model = \u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbefore_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mbefore_training should return the model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_cv:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\callback.py:386\u001b[39m, in \u001b[36mEarlyStopping.before_training\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbefore_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: _Model) -> _Model:\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28mself\u001b[39m.starting_round = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_boosted_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Booster) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save_best:\n\u001b[32m    388\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    389\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`save_best` is not applicable to the `cv` function as it doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    390\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m return a model.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    391\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py:3098\u001b[39m, in \u001b[36mBooster.num_boosted_rounds\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3096\u001b[39m rounds = ctypes.c_int()\n\u001b[32m   3097\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3098\u001b[39m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterBoostedRounds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rounds.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\core.py:323\u001b[39m, in \u001b[36m_check_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    313\u001b[39m \n\u001b[32m    314\u001b[39m \u001b[33;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    return value from API calls\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "\u001b[31mXGBoostError\u001b[39m: Invalid Input: 'gpu_hist', valid values are: {'approx', 'auto', 'exact', 'hist'}"
     ]
    }
   ],
   "source": [
    "# Option 1: Use default parameters from config\n",
    "params = XGBOOST_PARAMS.copy()\n",
    "\n",
    "# Option 2: Use custom parameters (uncomment to use)\n",
    "# params = {\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'eval_metric': 'auc',\n",
    "#     'tree_method': 'gpu_hist',  # Use 'hist' for CPU\n",
    "#     'max_depth': 8,\n",
    "#     'learning_rate': 0.05,\n",
    "#     'n_estimators': 500,\n",
    "#     'subsample': 0.8,\n",
    "#     'colsample_bytree': 0.8,\n",
    "#     'random_state': 42\n",
    "# }\n",
    "\n",
    "print(\"Training XGBoost model...\")\n",
    "print(f\"Parameters: {params}\")\n",
    "print(\"\\nThis may take a few minutes...\\n\")\n",
    "\n",
    "# Initialize and train\n",
    "xgb_model = XGBoostModel(params=params)\n",
    "xgb_model.train(\n",
    "    X_train_final, y_train,\n",
    "    X_val_final, y_val,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model_path = MODELS_DIR / 'xgboost_model.pkl'\n",
    "xgb_model.save_model(model_path)\n",
    "print(f\"\\n✓ Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions...\")\n",
    "\n",
    "# Predictions on validation set\n",
    "y_val_proba = xgb_model.predict_proba(X_val_final)\n",
    "y_val_pred = xgb_model.predict(X_val_final)\n",
    "\n",
    "# Predictions on test set\n",
    "y_test_proba = xgb_model.predict_proba(X_test_final)\n",
    "y_test_pred = xgb_model.predict(X_test_final)\n",
    "\n",
    "print(f\"\\n✓ Validation predictions: {len(y_val_proba):,}\")\n",
    "print(f\"✓ Test predictions: {len(y_test_proba):,}\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "results_df = pd.DataFrame({\n",
    "    'True_Label': y_test[:10].values,\n",
    "    'Predicted_Probability': y_test_proba[:10],\n",
    "    'Predicted_Label': y_test_pred[:10]\n",
    "})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator()\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"=\"*80)\n",
    "print(\"VALIDATION SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "val_metrics = evaluator.evaluate(\n",
    "    y_val, y_val_proba,\n",
    "    threshold=0.5,\n",
    "    model_name=\"XGBoost_Validation\"\n",
    ")\n",
    "\n",
    "# Display validation metrics\n",
    "print(\"\\nValidation Metrics:\")\n",
    "for metric, value in val_metrics.items():\n",
    "    if isinstance(value, (int, float)) and metric != 'threshold':\n",
    "        print(f\"  {metric}: {value:.4f}\" if isinstance(value, float) else f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"=\"*80)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_metrics = evaluator.evaluate(\n",
    "    y_test, y_test_proba,\n",
    "    threshold=0.5,\n",
    "    model_name=\"XGBoost_Test\"\n",
    ")\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nTest Metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    if isinstance(value, (int, float)) and metric != 'threshold':\n",
    "        print(f\"  {metric}: {value:.4f}\" if isinstance(value, float) else f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all evaluation plots for validation set\n",
    "print(\"Generating validation plots...\")\n",
    "val_figures = evaluator.evaluate_all_plots(\n",
    "    y_val, y_val_proba,\n",
    "    model_name=\"XGBoost_Validation\",\n",
    "    threshold=0.5,\n",
    "    save=True\n",
    ")\n",
    "print(\"✓ Validation plots saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all evaluation plots for test set\n",
    "print(\"Generating test plots...\")\n",
    "test_figures = evaluator.evaluate_all_plots(\n",
    "    y_test, y_test_proba,\n",
    "    model_name=\"XGBoost_Test\",\n",
    "    threshold=0.5,\n",
    "    save=True\n",
    ")\n",
    "print(\"✓ Test plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = xgb_model.get_feature_importance(importance_type='gain')\n",
    "\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(\"=\"*80)\n",
    "feature_importance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "xgb_model.plot_feature_importance(\n",
    "    top_n=20, \n",
    "    importance_type='gain',\n",
    "    save_path=evaluator.figures_dir / 'xgboost_feature_importance.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal thresholds for different metrics\n",
    "print(\"Threshold Optimization (on validation set):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for metric in ['f1', 'precision', 'recall']:\n",
    "    optimal_threshold, optimal_score = evaluator.optimize_threshold(\n",
    "        y_val, y_val_proba, metric=metric\n",
    "    )\n",
    "    print(f\"{metric.upper():<15} Threshold: {optimal_threshold:.4f}, Score: {optimal_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Generate Comparison Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison report\n",
    "results_dict = {\n",
    "    'XGBoost_Validation': val_metrics,\n",
    "    'XGBoost_Test': test_metrics\n",
    "}\n",
    "\n",
    "report_df = evaluator.generate_report(\n",
    "    results_dict,\n",
    "    output_path=evaluator.reports_dir / 'xgboost_evaluation_report.csv'\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation Report:\")\n",
    "report_df[['roc_auc', 'accuracy', 'precision', 'recall', 'f1_score', 'n_samples', 'n_positive', 'n_negative']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 DATASETS USED:\")\n",
    "print(f\"  Training data: {DATASET_CONFIG['train_dataset']} ({len(train_df):,} rows)\")\n",
    "print(f\"  Test data: {DATASET_CONFIG['test_dataset']} ({len(test_df):,} rows)\")\n",
    "print(f\"  Train samples: {len(X_train):,}\")\n",
    "print(f\"  Validation samples: {len(X_val):,}\")\n",
    "print(f\"  Test samples: {len(X_test):,}\")\n",
    "\n",
    "print(f\"\\n✓ Model saved to: {model_path}\")\n",
    "print(f\"✓ Figures saved to: {evaluator.figures_dir}\")\n",
    "print(f\"✓ Reports saved to: {evaluator.reports_dir}\")\n",
    "\n",
    "print(f\"\\n📈 PERFORMANCE SUMMARY:\")\n",
    "print(f\"  Validation AUC: {val_metrics['roc_auc']:.4f}\")\n",
    "print(f\"  Test AUC: {test_metrics['roc_auc']:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Test F1-Score: {test_metrics['f1_score']:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
